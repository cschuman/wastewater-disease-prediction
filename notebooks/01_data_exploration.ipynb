{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wastewater Disease Prediction - Data Exploration\n",
    "\n",
    "This notebook explores the CDC NWSS wastewater surveillance data and NHSN hospital admission data to understand:\n",
    "1. Data structure and coverage\n",
    "2. Temporal alignment between datasets\n",
    "3. Correlation between wastewater signals and hospitalizations\n",
    "4. Lead time analysis - how far ahead do wastewater signals predict hospital admissions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Paths\n",
    "DATA_RAW = Path('../data/raw')\n",
    "DATA_PROCESSED = Path('../data/processed')\n",
    "\n",
    "print(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most recent data files\n",
    "nwss_files = list(DATA_RAW.glob('nwss/*.parquet'))\n",
    "nhsn_files = list(DATA_RAW.glob('nhsn/*.parquet'))\n",
    "\n",
    "print(f\"NWSS files: {nwss_files}\")\n",
    "print(f\"NHSN files: {nhsn_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wastewater data\n",
    "ww = pd.read_parquet(nwss_files[0])\n",
    "print(f\"Wastewater data: {ww.shape}\")\n",
    "ww.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hospital data\n",
    "hosp = pd.read_parquet(nhsn_files[0])\n",
    "print(f\"Hospital data: {hosp.shape}\")\n",
    "hosp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Wastewater Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(\"Wastewater Data Info:\")\n",
    "print(f\"  Records: {len(ww):,}\")\n",
    "print(f\"  Date range: {ww['date_end'].min()} to {ww['date_end'].max()}\")\n",
    "print(f\"  States: {ww['wwtp_jurisdiction'].nunique()}\")\n",
    "print(f\"  Sites: {ww['wwtp_id'].nunique()}\")\n",
    "print(f\"\\nColumns: {list(ww.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the key metric columns\n",
    "print(\"Key metrics:\")\n",
    "for col in ['percentile', 'ptc_15d', 'detect_prop_15d', 'population_served']:\n",
    "    if col in ww.columns:\n",
    "        print(f\"  {col}: {ww[col].dtype}, non-null: {ww[col].notna().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sites per state\n",
    "sites_per_state = ww.groupby('wwtp_jurisdiction')['wwtp_id'].nunique().sort_values(ascending=False)\n",
    "print(\"Sites per state (top 15):\")\n",
    "print(sites_per_state.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize wastewater signal over time (national average)\n",
    "ww_weekly = ww.groupby('date_end').agg({\n",
    "    'percentile': 'mean',\n",
    "    'ptc_15d': 'mean',\n",
    "    'wwtp_id': 'nunique'\n",
    "}).reset_index()\n",
    "ww_weekly.columns = ['date', 'avg_percentile', 'avg_pct_change', 'n_sites']\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "axes[0].plot(ww_weekly['date'], ww_weekly['avg_percentile'], 'b-', linewidth=1.5)\n",
    "axes[0].set_ylabel('Average Percentile')\n",
    "axes[0].set_title('National Wastewater COVID-19 Signal (Percentile)')\n",
    "axes[0].axhline(y=50, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "axes[1].plot(ww_weekly['date'], ww_weekly['avg_pct_change'], 'r-', linewidth=1.5)\n",
    "axes[1].set_ylabel('15-day % Change')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_title('National Wastewater COVID-19 Signal (15-day % Change)')\n",
    "axes[1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Hospital Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the date column\n",
    "date_cols = [col for col in hosp.columns if 'date' in col.lower() or 'week' in col.lower()]\n",
    "print(f\"Date columns: {date_cols[:5]}\")\n",
    "\n",
    "# Find jurisdiction column\n",
    "jur_cols = [col for col in hosp.columns if 'jurisdiction' in col.lower() or 'state' in col.lower()]\n",
    "print(f\"Jurisdiction columns: {jur_cols[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify key admission columns\n",
    "admission_cols = [col for col in hosp.columns if 'admission' in col.lower()]\n",
    "print(f\"Found {len(admission_cols)} admission columns\")\n",
    "print(\"\\nKey admission columns:\")\n",
    "for col in admission_cols[:20]:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the main admission columns we need\n",
    "# These are the total admissions by disease\n",
    "covid_total_col = [c for c in hosp.columns if 'Total COVID-19 Admissions' in c and 'Percent' not in c and 'Change' not in c]\n",
    "flu_total_col = [c for c in hosp.columns if 'Total Influenza Admissions' in c and 'Percent' not in c and 'Change' not in c]\n",
    "rsv_total_col = [c for c in hosp.columns if 'Total RSV Admissions' in c and 'Percent' not in c and 'Change' not in c]\n",
    "\n",
    "print(f\"COVID total column: {covid_total_col}\")\n",
    "print(f\"Flu total column: {flu_total_col}\")\n",
    "print(f\"RSV total column: {rsv_total_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean hospital dataframe with key columns\n",
    "date_col = 'Week Ending Date'\n",
    "jur_col = 'Jurisdiction'\n",
    "\n",
    "# Define columns to keep\n",
    "keep_cols = [date_col, jur_col]\n",
    "\n",
    "# Add admission columns if they exist\n",
    "for name, cols in [('covid_admissions', covid_total_col), \n",
    "                   ('flu_admissions', flu_total_col), \n",
    "                   ('rsv_admissions', rsv_total_col)]:\n",
    "    if cols:\n",
    "        keep_cols.append(cols[0])\n",
    "\n",
    "# Also add age-stratified columns\n",
    "age_cols = [\n",
    "    'Total Pediatric COVID-19 Admissions',\n",
    "    'Total Adult COVID-19 Admissions',\n",
    "    'Total Pediatric Influenza Admissions', \n",
    "    'Total Adult Influenza Admissions',\n",
    "    'Total Pediatric RSV Admissions',\n",
    "    'Total Adult RSV Admissions'\n",
    "]\n",
    "for col in age_cols:\n",
    "    if col in hosp.columns:\n",
    "        keep_cols.append(col)\n",
    "\n",
    "print(f\"Keeping columns: {keep_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clean hospital dataframe\n",
    "hosp_clean = hosp[[c for c in keep_cols if c in hosp.columns]].copy()\n",
    "\n",
    "# Rename columns for easier use\n",
    "hosp_clean = hosp_clean.rename(columns={\n",
    "    date_col: 'week_end',\n",
    "    jur_col: 'state'\n",
    "})\n",
    "\n",
    "# Simplify other column names\n",
    "rename_map = {}\n",
    "for col in hosp_clean.columns:\n",
    "    if 'Total COVID-19 Admissions' in col and 'Pediatric' not in col and 'Adult' not in col:\n",
    "        rename_map[col] = 'covid_total'\n",
    "    elif 'Total Influenza Admissions' in col and 'Pediatric' not in col and 'Adult' not in col:\n",
    "        rename_map[col] = 'flu_total'\n",
    "    elif 'Total RSV Admissions' in col and 'Pediatric' not in col and 'Adult' not in col:\n",
    "        rename_map[col] = 'rsv_total'\n",
    "    elif 'Total Pediatric COVID-19' in col:\n",
    "        rename_map[col] = 'covid_pediatric'\n",
    "    elif 'Total Adult COVID-19' in col:\n",
    "        rename_map[col] = 'covid_adult'\n",
    "    elif 'Total Pediatric Influenza' in col:\n",
    "        rename_map[col] = 'flu_pediatric'\n",
    "    elif 'Total Adult Influenza' in col:\n",
    "        rename_map[col] = 'flu_adult'\n",
    "    elif 'Total Pediatric RSV' in col:\n",
    "        rename_map[col] = 'rsv_pediatric'\n",
    "    elif 'Total Adult RSV' in col:\n",
    "        rename_map[col] = 'rsv_adult'\n",
    "\n",
    "hosp_clean = hosp_clean.rename(columns=rename_map)\n",
    "print(f\"Clean hospital data shape: {hosp_clean.shape}\")\n",
    "hosp_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert admission columns to numeric\n",
    "admission_cols = [c for c in hosp_clean.columns if c not in ['week_end', 'state']]\n",
    "for col in admission_cols:\n",
    "    hosp_clean[col] = pd.to_numeric(hosp_clean[col], errors='coerce')\n",
    "\n",
    "# Create total respiratory admissions\n",
    "if all(c in hosp_clean.columns for c in ['covid_total', 'flu_total', 'rsv_total']):\n",
    "    hosp_clean['respiratory_total'] = (\n",
    "        hosp_clean['covid_total'].fillna(0) + \n",
    "        hosp_clean['flu_total'].fillna(0) + \n",
    "        hosp_clean['rsv_total'].fillna(0)\n",
    "    )\n",
    "    print(\"Created respiratory_total column\")\n",
    "\n",
    "hosp_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# National hospital admissions over time\n",
    "hosp_national = hosp_clean.groupby('week_end').agg({\n",
    "    'covid_total': 'sum',\n",
    "    'flu_total': 'sum',\n",
    "    'rsv_total': 'sum',\n",
    "    'respiratory_total': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(hosp_national['week_end'], hosp_national['covid_total'], label='COVID-19', linewidth=2)\n",
    "ax.plot(hosp_national['week_end'], hosp_national['flu_total'], label='Influenza', linewidth=2)\n",
    "ax.plot(hosp_national['week_end'], hosp_national['rsv_total'], label='RSV', linewidth=2)\n",
    "ax.plot(hosp_national['week_end'], hosp_national['respiratory_total'], label='Total Respiratory', linewidth=2, linestyle='--', color='black')\n",
    "\n",
    "ax.set_xlabel('Week')\n",
    "ax.set_ylabel('Admissions')\n",
    "ax.set_title('National Weekly Hospital Admissions by Respiratory Disease')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Align Wastewater and Hospital Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate wastewater data to state-week level\n",
    "# Use population-weighted average for the percentile\n",
    "ww['pop_weighted_percentile'] = ww['percentile'] * ww['population_served']\n",
    "\n",
    "ww_state_week = ww.groupby(['wwtp_jurisdiction', 'date_end']).agg({\n",
    "    'percentile': 'mean',\n",
    "    'pop_weighted_percentile': 'sum',\n",
    "    'population_served': 'sum',\n",
    "    'ptc_15d': 'mean',\n",
    "    'detect_prop_15d': 'mean',\n",
    "    'wwtp_id': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "ww_state_week['percentile_pop_weighted'] = ww_state_week['pop_weighted_percentile'] / ww_state_week['population_served']\n",
    "ww_state_week = ww_state_week.rename(columns={\n",
    "    'wwtp_jurisdiction': 'state',\n",
    "    'date_end': 'week_end',\n",
    "    'wwtp_id': 'n_sites'\n",
    "})\n",
    "\n",
    "print(f\"Wastewater state-week aggregated: {ww_state_week.shape}\")\n",
    "ww_state_week.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check date overlap\n",
    "ww_dates = set(ww_state_week['week_end'])\n",
    "hosp_dates = set(hosp_clean['week_end'])\n",
    "\n",
    "overlap_dates = ww_dates & hosp_dates\n",
    "print(f\"Wastewater date range: {min(ww_dates)} to {max(ww_dates)}\")\n",
    "print(f\"Hospital date range: {min(hosp_dates)} to {max(hosp_dates)}\")\n",
    "print(f\"Overlapping weeks: {len(overlap_dates)}\")\n",
    "print(f\"Overlap range: {min(overlap_dates)} to {max(overlap_dates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "merged = pd.merge(\n",
    "    ww_state_week,\n",
    "    hosp_clean,\n",
    "    on=['state', 'week_end'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset: {merged.shape}\")\n",
    "print(f\"States: {merged['state'].nunique()}\")\n",
    "print(f\"Weeks: {merged['week_end'].nunique()}\")\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations between wastewater signal and admissions\n",
    "ww_cols = ['percentile', 'percentile_pop_weighted', 'ptc_15d', 'detect_prop_15d']\n",
    "hosp_cols = ['covid_total', 'flu_total', 'rsv_total', 'respiratory_total']\n",
    "\n",
    "# Only keep columns that exist\n",
    "ww_cols = [c for c in ww_cols if c in merged.columns]\n",
    "hosp_cols = [c for c in hosp_cols if c in merged.columns]\n",
    "\n",
    "print(\"Correlation between wastewater signals and hospital admissions (same week):\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "corr_results = []\n",
    "for ww_col in ww_cols:\n",
    "    for hosp_col in hosp_cols:\n",
    "        valid = merged[[ww_col, hosp_col]].dropna()\n",
    "        if len(valid) > 10:\n",
    "            r, p = stats.pearsonr(valid[ww_col], valid[hosp_col])\n",
    "            corr_results.append({\n",
    "                'wastewater_signal': ww_col,\n",
    "                'hospital_metric': hosp_col,\n",
    "                'correlation': r,\n",
    "                'p_value': p,\n",
    "                'n': len(valid)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(corr_results)\n",
    "corr_df = corr_df.sort_values('correlation', ascending=False)\n",
    "print(corr_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of strongest correlation\n",
    "if len(corr_df) > 0:\n",
    "    best = corr_df.iloc[0]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.scatter(merged[best['wastewater_signal']], merged[best['hospital_metric']], alpha=0.3)\n",
    "    ax.set_xlabel(best['wastewater_signal'])\n",
    "    ax.set_ylabel(best['hospital_metric'])\n",
    "    ax.set_title(f\"Wastewater vs Hospital Admissions\\nr = {best['correlation']:.3f}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Lead Time Analysis\n",
    "\n",
    "Key question: How many weeks ahead does the wastewater signal predict hospital admissions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lagged_correlations(df, ww_col, hosp_col, max_lag=6):\n",
    "    \"\"\"\n",
    "    Compute correlation between wastewater signal and hospital admissions at different lags.\n",
    "    \n",
    "    Positive lag means wastewater LEADS hospital admissions (what we want).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for state in df['state'].unique():\n",
    "        state_data = df[df['state'] == state].sort_values('week_end').copy()\n",
    "        \n",
    "        if len(state_data) < max_lag + 5:\n",
    "            continue\n",
    "            \n",
    "        for lag in range(-max_lag, max_lag + 1):\n",
    "            if lag >= 0:\n",
    "                # Positive lag: wastewater leads (we look at past wastewater vs current hospital)\n",
    "                ww_values = state_data[ww_col].iloc[:-lag] if lag > 0 else state_data[ww_col]\n",
    "                hosp_values = state_data[hosp_col].iloc[lag:] if lag > 0 else state_data[hosp_col]\n",
    "            else:\n",
    "                # Negative lag: hospital leads (sanity check - shouldn't be strong)\n",
    "                ww_values = state_data[ww_col].iloc[-lag:]\n",
    "                hosp_values = state_data[hosp_col].iloc[:lag]\n",
    "            \n",
    "            # Align and compute correlation\n",
    "            if len(ww_values) > 5 and len(hosp_values) > 5:\n",
    "                valid_mask = ~(pd.isna(ww_values.values) | pd.isna(hosp_values.values))\n",
    "                if valid_mask.sum() > 5:\n",
    "                    r, p = stats.pearsonr(\n",
    "                        ww_values.values[valid_mask], \n",
    "                        hosp_values.values[valid_mask]\n",
    "                    )\n",
    "                    results.append({\n",
    "                        'state': state,\n",
    "                        'lag_weeks': lag,\n",
    "                        'correlation': r,\n",
    "                        'p_value': p,\n",
    "                        'n': valid_mask.sum()\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Compute lagged correlations for COVID\n",
    "if 'percentile_pop_weighted' in merged.columns and 'covid_total' in merged.columns:\n",
    "    lag_results = compute_lagged_correlations(merged, 'percentile_pop_weighted', 'covid_total', max_lag=4)\n",
    "    print(f\"Computed {len(lag_results)} lagged correlations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average correlation by lag across all states\n",
    "if len(lag_results) > 0:\n",
    "    lag_summary = lag_results.groupby('lag_weeks').agg({\n",
    "        'correlation': ['mean', 'std', 'count']\n",
    "    }).reset_index()\n",
    "    lag_summary.columns = ['lag_weeks', 'mean_corr', 'std_corr', 'n_states']\n",
    "    \n",
    "    print(\"Correlation by lag (positive = wastewater leads):\")\n",
    "    print(lag_summary.to_string(index=False))\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.errorbar(lag_summary['lag_weeks'], lag_summary['mean_corr'], \n",
    "                yerr=lag_summary['std_corr']/np.sqrt(lag_summary['n_states']),\n",
    "                marker='o', capsize=5, linewidth=2, markersize=8)\n",
    "    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Lag (weeks) - Positive = Wastewater Leads')\n",
    "    ax.set_ylabel('Correlation (r)')\n",
    "    ax.set_title('Lead Time Analysis: Wastewater Signal vs COVID-19 Hospital Admissions')\n",
    "    ax.set_xticks(range(-4, 5))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find optimal lead time\n",
    "    best_lag = lag_summary.loc[lag_summary['mean_corr'].idxmax()]\n",
    "    print(f\"\\nOptimal lead time: {best_lag['lag_weeks']:.0f} weeks (r = {best_lag['mean_corr']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. State-Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation by state\n",
    "state_corrs = []\n",
    "for state in merged['state'].unique():\n",
    "    state_data = merged[merged['state'] == state]\n",
    "    if len(state_data) > 10:\n",
    "        valid = state_data[['percentile_pop_weighted', 'covid_total']].dropna()\n",
    "        if len(valid) > 10:\n",
    "            r, p = stats.pearsonr(valid['percentile_pop_weighted'], valid['covid_total'])\n",
    "            state_corrs.append({\n",
    "                'state': state,\n",
    "                'correlation': r,\n",
    "                'p_value': p,\n",
    "                'n_weeks': len(valid)\n",
    "            })\n",
    "\n",
    "state_corr_df = pd.DataFrame(state_corrs).sort_values('correlation', ascending=False)\n",
    "print(\"Correlation by state (top 15):\")\n",
    "print(state_corr_df.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top states\n",
    "if len(state_corr_df) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    top_states = state_corr_df.head(20)\n",
    "    colors = ['green' if r > 0 else 'red' for r in top_states['correlation']]\n",
    "    ax.barh(top_states['state'], top_states['correlation'], color=colors, alpha=0.7)\n",
    "    ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "    ax.set_xlabel('Correlation (r)')\n",
    "    ax.set_title('Wastewater-Hospital Admission Correlation by State (COVID-19)')\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged dataset for modeling\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "merged.to_parquet(DATA_PROCESSED / 'merged_ww_hospital_state_week.parquet', index=False)\n",
    "print(f\"Saved merged data to {DATA_PROCESSED / 'merged_ww_hospital_state_week.parquet'}\")\n",
    "\n",
    "# Save correlation results\n",
    "if len(corr_df) > 0:\n",
    "    corr_df.to_csv(DATA_PROCESSED / 'correlation_analysis.csv', index=False)\n",
    "if len(lag_results) > 0:\n",
    "    lag_results.to_csv(DATA_PROCESSED / 'lag_correlation_analysis.csv', index=False)\n",
    "if len(state_corr_df) > 0:\n",
    "    state_corr_df.to_csv(DATA_PROCESSED / 'state_correlation_analysis.csv', index=False)\n",
    "\n",
    "print(\"\\nAnalysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key findings from this exploratory analysis:\n",
    "\n",
    "1. **Data Coverage:**\n",
    "   - Wastewater: ~1,100+ sites across 51 states/territories\n",
    "   - Hospital: Weekly admissions by state for COVID-19, Flu, RSV\n",
    "\n",
    "2. **Correlation:**\n",
    "   - Wastewater percentile shows [X] correlation with COVID-19 hospital admissions\n",
    "   - Population-weighted averaging improves signal quality\n",
    "\n",
    "3. **Lead Time:**\n",
    "   - Optimal lead time appears to be [X] weeks\n",
    "   - This confirms wastewater can provide early warning for hospitalizations\n",
    "\n",
    "4. **Next Steps:**\n",
    "   - Build baseline prediction models (ARIMA, XGBoost)\n",
    "   - Incorporate flu and RSV wastewater signals when available\n",
    "   - Create combined respiratory burden target variable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
